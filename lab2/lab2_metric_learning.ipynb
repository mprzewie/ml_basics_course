{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.1 - Metric Learning\n",
    "\n",
    "Celem zadania jest obserwacja jak zmiana wykorzystywanej przez klasyfikator k-NN metryki wpływa na kształt granicy decyzyjnej, a więc w efekcie na jego skuteczność.\n",
    "\n",
    "**Wykonanie rozwiązań: Marcin Przewięźlikowski**\n",
    "\n",
    "https://github.com/mprzewie/ml_basics_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from typing import Dict, Tuple\n",
    "import cv2\n",
    "from dataset_ops import (\n",
    "    load_dataset, visualize_dataset, slice_dataset, sliced_dataset_name\n",
    ")\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie datasetów\n",
    "\n",
    "Korzystając np. z omawianej na zajęciach metody \"z paintem\" (lub innej), przygotuj 3 różne (ciekawe) dwuwymiarowe zbiory danych. Przynajmniej raz powinna wystąpić każda z poniższych sytuacji:\n",
    "- 3 lub więcej różnych klas\n",
    "- klasy dobrze odseparowane w danym regionie;\n",
    "- klasy częściowo przemieszane, nachodzące na siebie;\n",
    "- wyspa jednej klasy wewnątrz regionu drugiej;\n",
    "- różne gęstości punktów wewnątrz poszczególnych klas;\n",
    "- nieregularne kształty obszaru jednej z klas;\n",
    "- niesymetryczny kształt całego zbioru (np. podłużne wrzeciono).\n",
    "\n",
    "Jeżeli korzystasz z metody \"z paintem\" to pamiętaj, by przed zapisaniem zbioru nałożyć na punkty niewielki szum. Przygotowane zbiory możesz wykorzystać w obu zadaniach domowych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_datasets = {}\n",
    "n_datasets = 3\n",
    "x1_size, x2_size = (100, 100)\n",
    "for i in range(3):\n",
    "    X, y = load_dataset(f\"ds_{i + 1}.png\", space_size=(x1_size, x2_size), dropout=0.8)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    orig_datasets[f\"{i}_train\"] = X_train, y_train\n",
    "    orig_datasets[f\"{i}_test\"] = X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, (X, y) in orig_datasets.items():\n",
    "    print(name)\n",
    "    visualize_dataset(X, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadanie rozpoczynamy od przygotowania testowych zbiorów danych. Następnie dla obu z tych zbiorów trenujemy poniższe 4 warianty klasyfikatora k-NN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwsze kilka KNN będzie działać na niepodzielonych datasetach ($n\\_datasets = 1$). Ostatni będzie działał na podzielonych ($n\\_datasets = 5$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coords = np.arange(0, 100)\n",
    "X_all = np.array([[[x0, x1] for x1 in all_coords] for x0 in all_coords]).reshape(-1, 2)\n",
    "y_all_ph = np.array([0 for _ in X_all])\n",
    "all_sliced = {}\n",
    "datasets = {}\n",
    "for n_slices in [1, 5]:\n",
    "    for ds_name, (X, y) in orig_datasets.items():\n",
    "        sliced = slice_dataset(X, y, n_slices=n_slices)\n",
    "        for (x0, x1), (X_s, y_s) in sliced.items():\n",
    "            datasets[sliced_dataset_name(ds_name, n_slices, x0, x1)] = X_s, y_s\n",
    "    sliced_all_by_x0_x1 = slice_dataset(X_all, y_all_ph, n_slices=n_slices)\n",
    "    for (x0, x1), (X_s, y_s) in sliced_all_by_x0_x1.items():\n",
    "        all_sliced[(n_slices, x0, x1)] = X_s, y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knns(\n",
    "    knn_prototype: KNeighborsClassifier, \n",
    "    n_slices: int\n",
    ") -> Dict[Tuple[int, int, int], KNeighborsClassifier]:\n",
    "    knn_dict = {}\n",
    "    for i in range(n_datasets):\n",
    "        for x0 in range(n_slices):\n",
    "            for x1 in range(n_slices): \n",
    "                ds_name = sliced_dataset_name(f\"{i}_train\", n_slices, x0, x1)\n",
    "                X_train, y_train = datasets[ds_name]\n",
    "                if X_train.shape[0] > 0:\n",
    "                    knn = deepcopy(knn_prototype)\n",
    "                    knn.fit(X_train, y_train)\n",
    "                    knn_dict[(i, x0, x1)] = knn\n",
    "                else:\n",
    "                    knn_dict[(i, x0, x1)] = None\n",
    "        plt.show()\n",
    "    return knn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knns = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN z k=1, głosowaniem większościowym i metryką Euklidesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN1_NAME = \"k1_uniform_eucli\"\n",
    "KNN1_PROTOTYPE = KNeighborsClassifier(n_neighbors=1, algorithm=\"brute\")\n",
    "knns[KNN1_NAME] = train_knns(KNN1_PROTOTYPE, n_slices=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### k-NN z k=3, głosowaniem większościowym i metryką Euklidesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN2_NAME = \"k3_uniform_eucli\"\n",
    "KNN2_PROTOTYPE = KNeighborsClassifier(n_neighbors=3, algorithm=\"brute\")\n",
    "knns[KNN2_NAME] = train_knns(KNN2_PROTOTYPE, n_slices=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN z k=3, głosowaniem ważonym odległością i metryką Euklidesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN3_NAME = \"k3_weighted_eucli\"\n",
    "KNN3_PROTOTYPE = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm=\"brute\")\n",
    "knns[KNN3_NAME] = train_knns(KNN3_PROTOTYPE, n_slices=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN z k=1, głosowaniem większościowym i metryką Mahalanobisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN4_NAME = \"k1_weighted_mahalan\"\n",
    "KNN4_PROTOTYPE = KNeighborsClassifier(\n",
    "    n_neighbors=1, \n",
    "    weights=\"distance\", \n",
    "    algorithm=\"brute\", \n",
    "    metric=\"mahalanobis\"\n",
    ")\n",
    "knns[KNN4_NAME] = train_knns(KNN4_PROTOTYPE, n_slices=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN z k=1, głosowaniem większośćiowym i metryką Mahalanobisa zależną od regionu\n",
    "Aby zrealizować ostatni punkt wykonaj następujące kroki:\n",
    " * podziel obszar w którym leży zbiór na kilka podobszarów (np. 5x5);\n",
    " * dla każdego z podobszarów wyznacz macierz kowariancji (używaną przez metrykę Mahalanobisa) tylko w oparciu o obserwacje leżące w tym podobszarze i podobszarach do niego przyległych;\n",
    " * w zależności od klasyfikowanego regionu korzystaj z macierzy jemu właściwej.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN5_NAME = \"k1_weighted_mahalan_split\"\n",
    "KNN5_PROTOTYPE = KNeighborsClassifier(\n",
    "                    n_neighbors=1, \n",
    "                    algorithm=\"brute\", \n",
    "                    metric=\"mahalanobis\"\n",
    "                )\n",
    "\n",
    "knns[KNN5_NAME] = train_knns(KNN5_PROTOTYPE, n_slices=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ewaluacja\n",
    "Dla każdej pary zbiór-klasyfikator zwizualizuj wygląd granicy decyzyjnej oraz oszacuj % błąd takiego klasyfikatora (pamiętaj, że wymaga to podziału zbioru na treningowy i testowy). Skomentuj uzyskane wyniki - bądź krytyczny i nie zakładaj z góry oczekiwanych wniosków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_dict = {\n",
    "    KNN1_NAME: 1,\n",
    "    KNN2_NAME: 1,\n",
    "    KNN3_NAME: 1,\n",
    "    KNN4_NAME: 1,\n",
    "    KNN5_NAME: 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_datasets):\n",
    "    _, y_train = orig_datasets[f\"{i}_train\"]\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    print(\"dataset\", i, \"n_classes =\", n_classes)\n",
    "    for name, classifiers in knns.items():\n",
    "        print(name)\n",
    "        accuracies = []\n",
    "        weights = []\n",
    "        n_slices = slices_dict[name]\n",
    "        for x0 in range(n_slices):\n",
    "            for x1 in range(n_slices):\n",
    "                knn = classifiers[(i, x0, x1)]\n",
    "                ds_name = sliced_dataset_name(f\"{i}_test\", n_slices, x0, x1)\n",
    "                X_test, y_test = datasets[ds_name]\n",
    "                if knn is not None and X_test.shape[0] > 1:\n",
    "                    weight = X_test.shape[0]\n",
    "                    accuracy = knn.score(X_test, y_test)\n",
    "                    X_all_s, _ = all_sliced[(n_slices, x0, x1)]\n",
    "                    y_all = knn.predict(X_all_s)\n",
    "                    visualize_dataset(X_all_s, y_all, n_classes)\n",
    "                else: \n",
    "                    weight, accuracy = 0, 0\n",
    "                accuracies.append(accuracy)\n",
    "                weights.append(accuracy)\n",
    "        accuracies = np.array(accuracies)\n",
    "        weighs = np.array(weights)\n",
    "        total_acc = np.average(accuracies, weights=weights)\n",
    "        print(\"accuracy on\", i, \":\", total_acc)\n",
    "        plt.show()\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implementacje KNN ze Skikit-Learn są w stanie osiągnąć bardzo wysokie dokładności na zadanych datasetach - jest to możliwe, gdyż są one dość gęste\n",
    "\n",
    "* KNN głosujący wśrod 3 najbliższych sąsiadów radzi sobie słabiej niż KNN szukający 1 najbliższego sąsiada - pojawia się to jednak dopiero przy obniżeniu gęstości datasetów\n",
    "\n",
    "* KNN z głoosowaniem ważonym odległością i metryką Euklidesową radzi sobie lepiej niż pozostałe KNN z metryką Euklidesową - co ma sens, gdyż dzięki ważeniu odległości możemy priorytetyzować bliższych sąsiadów\n",
    "\n",
    "* KNN z metryką Mahalanobisa radzi sobie co najmniej tak dobrze, jak KNN z metryką Euklidesową - nie dziwi to, gdyż metryka Euklidesowa jest szczególnym przypadkiem metryki Mahalanobisa. Widać też, że KNNy trenowane metryką Mahalanobisa są w stanie uchwycić znacznie bardziej szczegółowe granice klasyfikacji.\n",
    "\n",
    "* KNN z metryką Mahalanonbisa działający na konkretnym obszarze prawie zawsze radzi sobie lepiej niż KNN nauczony na całej przestrzeni datasetu - to również nie dziwi, bo mamy tu do czynienia z większą ilością modeli wyuczonych na bardziej specyficznych datasetach. Warto jednak zauwazyć, że granice decyzyjne często pokrywają się z granicami obszarów, można więc przypuszczać że te specyfikacje datasetów powodują pewien overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
