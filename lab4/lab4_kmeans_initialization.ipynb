{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.2 - Metody inicjalizacji k-means\n",
    "\n",
    "**Wykonanie rozwiązań: Marcin Przewięźlikowski**\n",
    "\n",
    "https://github.com/mprzewie/ml_basics_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster.k_means_ import _init_centroids\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "from typing import Dict, Any, Callable\n",
    "from matplotlib.colors import CSS4_COLORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór normalny\n",
    "Wygenerujmy zbiór danych wyglądający +- tak jak na załączonym rysunku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_per_cluster = 30\n",
    "Xs = []\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        cluster = np.random.randn(p_per_cluster, 2) + np.array([i, j]) * 6\n",
    "        Xs.append(cluster)\n",
    "\n",
    "X = np.concatenate(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchamiamy na nim algorytm k-means z k równym 9 i następującymi metodami inicjowania środków klastrów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inits = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random - z rozkładem jednostajnym po całym zakresie wartości;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inits[\"random\"] = lambda X: np.random.rand(9,2) * (X.max(axis=0) - X.min(axis=0)) + X.min(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Forgy - wybieramy k elementów ze zbioru jako początkowe środki;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inits[\"forgy\"] = lambda X: _init_centroids(X, 9, \"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Partition - losowo dzielimy zbiór na k klastrów, początkowy środek klastra to średnia z elementów które w ten sposób w nim się znalazły;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inits[\"random_partition\"] = lambda X: np.array([\n",
    "    X[np.random.randint(0, 9, X.shape[0])==i].mean(axis=0)\n",
    "    for i in range(9)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* k-means++ - wybieramy początkowe środki w sposób opisany w paperze z załącznika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inits[\"kmeans++\"] = lambda X: _init_centroids(X, 9, \"k-means++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenuję k-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeanses: Dict[str, KMeans] = {\n",
    "    init_name: KMeans(n_clusters=9, init=init_method(X), n_init=1).fit(X)\n",
    "    for (init_name, init_method) in inits.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_results_chart(X: np.ndarray, kmeanses: Dict[str, KMeans]):\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    fig.suptitle(\"Wizualizacja klasteryzacji w zależności od inicjalizacji\")\n",
    "    for (i, (init_name, kmeans)) in enumerate(kmeanses.items()):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        X_clusters = kmeans.predict(X)\n",
    "        plt.title(init_name)\n",
    "        for c in np.unique(X_clusters):\n",
    "            X_clustered = X[X_clusters==c]\n",
    "            p = plt.scatter(X_clustered[:, 0], X_clustered[:,1])\n",
    "            centre = kmeans.cluster_centers_[c]\n",
    "            plt.scatter([centre[0]], [centre[1]], marker=\"D\", c=\"white\", s=300)\n",
    "            plt.scatter([centre[0]], [centre[1]], marker=\"D\", c=p.get_facecolors(), s=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_results_chart(X, kmeanses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W klastryzacji tak symaetrycznego zbioru punktów przoduje $random\\_partition$ oraz $kmeans++$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszym celem jest uzyskanie wykresu jakości klastryzacji Q w zależności od numeru iteracji n dla wszystkich powyższych metod (wszystkie wyniki na jednym wykresie). Jakość Q rozumiemy jako wybraną metrykę jakości (np. Davies-Bouldin index czy Dunn index, może być dowolna rozsądna inna - ale nie Silhouette). Proces k-means jest silnie stochastyczny, więc eksperyment powtarzamy wielokrotnie, a na wykresie pokazujemy średni wynik i jego odchylenie standardowe jako errorbary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korzystam z metryki Calinskiego-Harabaza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_score(\n",
    "    init_method: Any, \n",
    "    X: np.ndarray, \n",
    "    max_iters: int, \n",
    "    n_clusters=9, \n",
    ") -> float:\n",
    "    labels = KMeans(\n",
    "        n_clusters=n_clusters, \n",
    "        init=init_method,\n",
    "        max_iter=max_iters,\n",
    "        n_init=1,\n",
    "        tol=0\n",
    "    ).fit_predict(X)\n",
    "    return calinski_harabaz_score(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_scores_measurements(\n",
    "    X: np.ndarray, \n",
    "    inits: Dict[str, Callable[[np.ndarray], np.ndarray]] = inits,\n",
    "    max_iters: int = 30, \n",
    "    n_trials: int = 15\n",
    "):\n",
    "    scores = {}\n",
    "    for init_name in inits.keys():\n",
    "        scores[init_name] = {}\n",
    "        for trial_no in range(n_trials):\n",
    "            init_method = inits[init_name](X)\n",
    "            scores[init_name][trial_no] = [\n",
    "                kmeans_score(init_method, X, iters)\n",
    "                for iters in range(1, max_iters)\n",
    "            ]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores =kmeans_scores_measurements(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_scores_chart(scores: Dict):\n",
    "    fig = plt.figure(figsize=(12,15))\n",
    "    for (i, init_name) in enumerate(inits.keys()):\n",
    "        all_trials_results = np.array(list(scores[init_name].values()))\n",
    "        means = all_trials_results.mean(axis=0)\n",
    "        stds = all_trials_results.std(axis=0) / 5\n",
    "        plt.errorbar(\n",
    "            [i for (i, _) in enumerate(means)], \n",
    "            means, \n",
    "            yerr=stds, \n",
    "            label=init_name,\n",
    "        )\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Calinsky-Harabaz score of k-menas with different initialization methods \\n\" + \n",
    "              \"Errorbars have been descaled 5 times, for the sake of readability of the chart\")\n",
    "    plt.xlabel(\"num_iters\")\n",
    "    plt.ylabel(\"calinsky-harabaz_score\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_scores_chart(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K-means++$ wyraźnie przebija pozostałe inicjalizacje. \n",
    "\n",
    "Zauważyć też można, że wykresy dość szybko się wypłaszczają, czyli że niezależnie od inicjalizacji, K-Means zbiega do rozwiązania już po kilkunastu iteracjach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Zbiór zepsuty\n",
    " Następnie \"psujemy zbiór\", dokonując następujących zmian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_clusters = {}\n",
    "p_per_cluster = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * jeden z okręgów znacząco powiększamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_clusters[\"big\"] = np.random.randn(p_per_cluster, 2) * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * jeden czynimi znacząco gęściej zapełnionym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_clusters[\"dense\"] = np.random.randn(p_per_cluster * 10, 2) * 1.5 + np.array([0, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * dwa zbliżamy mocno do siebie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_clusters[\"close1\"] = np.random.randn(p_per_cluster, 2) + np.array([12, 0])\n",
    "broken_clusters[\"close2\"] = np.random.randn(p_per_cluster, 2) + np.array([3,3]) + np.array([12, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * jednemu zmieniamy kształt z okrągłego na wrzecionowaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_clusters[\"huso\"] = np.random.randn(p_per_cluster, 2) * np.array([2, 0.5]) + np.array([12,12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * jeden znacząco oddalamy od pozostałych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_clusters[\"far\"] = np.random.randn(p_per_cluster, 2) + np.array([30, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_clusters[\"normal1\"] = np.random.randn(p_per_cluster, 2) + np.array([0, 20]) \n",
    "broken_clusters[\"normal2\"] = np.random.randn(p_per_cluster, 2) + np.array([20,0]) \n",
    "broken_clusters[\"normal3\"] = np.random.randn(p_per_cluster, 2) + np.array([20,10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "for (name, c) in broken_clusters.items():\n",
    "    ax.scatter(c[:,0], c[:,1], label=name)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powtarzamy obliczenia dla zmodyfikowanego zbioru - jakie efekty teraz uzyskaliśmy? Jaki był stan końcowy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_broken = np.concatenate(list(broken_clusters.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeanses_broken: Dict[str, KMeans] = {\n",
    "    init_name: KMeans(n_clusters=9, init=init_method(X_broken), n_init=1).fit(X_broken)\n",
    "    for (init_name, init_method) in inits.items()\n",
    "}\n",
    "kmeans_results_chart(X_broken, kmeanses_broken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ze sklastrowaniem zbioru zepsutego zdecydowanie najlepiej poradziło sobie $kmeans++$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalnie, dla obu zbiorów (oryginalnego i \"zepsutego\") uruchommy dla różnych k z zakresu od 1 do 20 i porównajmy finalne metryki jakości. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "k_range = range(2,21)\n",
    "for (ds_name, ds) in [(\"normal dataset\", X), (\"broken dataset\", X_broken)]:\n",
    "    scores = [\n",
    "        calinski_harabaz_score(\n",
    "            ds, KMeans(n_clusters=k).fit_predict(ds)\n",
    "        ) for k in k_range\n",
    "    ]\n",
    "    plt.plot(list(k_range), scores, label=ds_name)\n",
    "    \n",
    "plt.legend()\n",
    "plt.xticks(list(k_range))\n",
    "plt.xlabel(\"n_clusters\")\n",
    "plt.ylabel(\"Calinshy-Harabaz score\")\n",
    "plt.title(\"Calinsky-Harabaz score for k-means clustering with k++ initialization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czy na ich podstawie można stwierdzić, że optymalne k to 9 (bo tyle mamy klastrów)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy niezepsutym datasecie osiągamy maksymalną wartość punktacji C-H dla $K=9$, więc faktycznie można stwierdzić, że optymalne K=9.\n",
    "\n",
    "Przy datasecie niezepsutym, maksimum punktacji C-H jest dla $K=17$, czyli dla klasteryzacji wyglądającej tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=17).fit(X_broken)\n",
    "\n",
    "X_clusters = kmeans.predict(X_broken)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.title(\"Klasteryzacja zepsutego datasety dla $K=17$\")\n",
    "for c in np.unique(X_clusters):\n",
    "    X_clustered = X_broken[X_clusters==c]\n",
    "    p = plt.scatter(X_clustered[:, 0], X_clustered[:,1])\n",
    "\n",
    "    centre = kmeans.cluster_centers_[c]\n",
    "    plt.scatter([centre[0]], [centre[1]], marker=\"D\", c=\"white\", s=300)\n",
    "    plt.scatter([centre[0]], [centre[1]], marker=\"D\", c=p.get_facecolors(), s=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Był to jednak dataset trudny do sklastrowania, więc można było się spodziewać, że $K=9$ nie okaże się optymalne."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
